# In[8]:

import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
import datetime as dt
from scipy import stats
import scipy.special as special
import scipy.integrate as integrate
import scipy.optimize as optimize
import math as math

plt.rcParams.update({'font.size': 16, 'figure.figsize': [10.0, 8.0]})

workdir = get_ipython().magic('pwd')
print(workdir)


# In[122]:

class Slugtest_Well:

    def __init__(self, TotDepth, r_s, r_c, Le):

        self.TotDepth = TotDepth #Total well depth beneath ground level
        self.r_s = r_s #Borehole radius or radius of effective permeable gravel pack
        self.r_c = r_c #Well-casnig radius
        self.Le = Le #Screen length or length of effective permeable gravel pack
            
    def read_slugdata(self, filename):
        #Change folder to where data is
        get_ipython().magic('cd D:\\Kandidatarbete\\slugtestdata\\slugtest')
        
        #Load slugtest data and convert time to seconds
        self.slugtestdata = pd.read_excel(filename)
        get_ipython().magic('cd ..')
        self.slugtestdata['TimeStamp'] = pd.to_datetime(self.slugtestdata['TimeStamp'])
        self.slugtestdata['Seconds'] = self.slugtestdata['TimeStamp'].dt.hour*3600 + self.slugtestdata['TimeStamp'].dt.minute*60 + self.slugtestdata['TimeStamp'].dt.second - (self.slugtestdata['TimeStamp'].dt.hour.iloc[0]*3600 + self.slugtestdata['TimeStamp'].dt.minute.iloc[0]*60 + self.slugtestdata['TimeStamp'].dt.second.iloc[0])
# When the slugtest is preformed over more than a day the above will plott it double but is still readble if some things ignored
# By uncommenting the part below it should make the cases with different dates work, but will the make method for test during one day crash
#==============================================================================
#         if self.slugtestdata['TimeStamp'].dt.date.iloc[0]==self.slugtestdata['TimeStamp'].dt.date.iloc[-1]:
#             self.slugtestdata['Seconds'] = self.slugtestdata['TimeStamp'].dt.hour*3600 + self.slugtestdata['TimeStamp'].dt.minute*60 + self.slugtestdata['TimeStamp'].dt.second - (self.slugtestdata['TimeStamp'].dt.hour.iloc[0]*3600 + self.slugtestdata['TimeStamp'].dt.minute.iloc[0]*60 + self.slugtestdata['TimeStamp'].dt.second.iloc[0])  
#         else:
#             Seconds = []
#             for i in range(len(self.slugtestdata['TimeStamp'])):
#                 if self.slugtestdata['TimeStamp'].dt.date.iloc[0]==self.slugtestdata['TimeStamp'].dt.date.iloc[i]:
#                     Seconds.append(self.slugtestdata['TimeStamp'].dt.hour.iloc[i]*3600 + self.slugtestdata['TimeStamp'].dt.minute.iloc[i]*60 + self.slugtestdata['TimeStamp'].dt.second.iloc[i] - (self.slugtestdata['TimeStamp'].dt.hour.iloc[0]*3600 + self.slugtestdata['TimeStamp'].dt.minute.iloc[0]*60 + self.slugtestdata['TimeStamp'].dt.second.iloc[0]))
#                 else:
#                     Seconds.append(1*24*3600 + self.slugtestdata['TimeStamp'].dt.hour.iloc[i]*3600 + self.slugtestdata['TimeStamp'].dt.minute.iloc[i]*60 + self.slugtestdata['TimeStamp'].dt.second.iloc[i] - (self.slugtestdata['TimeStamp'].dt.hour.iloc[0]*3600 + self.slugtestdata['TimeStamp'].dt.minute.iloc[0]*60 + self.slugtestdata['TimeStamp'].dt.second.iloc[0])) 
#             self.slugtestdata['Seconds'] = Seconds
#==============================================================================
            
    def Datareform(self, initial_h, start, stop):
        # Pick out the span of the slugtest and calculate H/H_0 for the time
        self.initial_h = initial_h
        self.start = start
        self.stop= stop
        
        diff= abs(stop - start)
        Data_Y= self.slugtestdata['WaterLevel'][start:stop]
        
        Data_X= [i for i in range(1,diff+1)]
        
        Min= min(Data_Y)
        Max= max(Data_Y)
        if abs(initial_h- Min) < abs(initial_h-Max):
            h0 = Max
        elif abs(initial_h-Min) >abs(initial_h-Max):
            h0= Min
        print(h0)
        H_0 = abs(initial_h - h0)
        H_div_H0= [abs(initial_h-Data_Y.iloc[i] )/H_0 for i in range(diff)]
        
        Data_Y = H_div_H0
        plt.figure()
        plt.plot(Data_X, Data_Y)
        plt.xlabel('Time unit (s)')
        plt.ylabel(r'$\frac{H}{H_0}$')
        #returning the time span of the slugtest, Data_X
        #returning the H/H_0 during the span of the slugtest as Data_Y
        return Data_X, Data_Y
    
    def Hvorslevs_model(self, Data_X, Data_Y, p=[0,0]):
        self.Data_X = Data_X
        self.Data_Y = Data_Y
        
        # Plotting the original data
        plt.figure()
        plt.plot(Data_X, Data_Y, 'bo', ms= 2, alpha= 0.3, label= 'Original data')
        
        # Defining a function that calculates the Hydraulic conductivity when t_37 is known
        def Hvorslev(T_37):
            if abs(self.Le/self.r_s) > 8:
                return (self.r_c**2*np.log(self.Le/self.r_s))/ (2*self.Le* T_37)
            else:
                return "The screen length is not more that 8 times the borehole radius."
        
        # Making a linear regression of the original data
        slope, intercept, r_value, p_value, std_err = stats.linregress(Data_X, Data_Y)
        
        def linregg(slope, intercept, x):
            return (slope*x + intercept)
        #Plotting the result of the linear regression and the respective t_37
        Y_lr= [linregg(slope, intercept, i) for i in Data_X]
        plt.plot(Data_X, Y_lr, 'g-', label= 'Linear regression method')
        T_37_lr = (0.37-intercept)/slope
        plt.axhline(y=0.37, color='b', linestyle='--', alpha=0.3) 
        plt.axvline(x=T_37_lr, color='g', linestyle='--', alpha=0.3, label= r'$t_{37}$ for Linear regression')
        
        # Making a non-linear regression with the assuption that the data for Hvorslev's method follows func 
        def func(x,p1,p2):
            return p1*np.exp(-1*p2*x)
        
        # Guess of parameters and then using the optimize.curve_fit to find the values of the parameters
        params= [1,1]
        popt, pcov = optimize.curve_fit(func, Data_X, Data_Y, params[:], method= 'lm')
        Y_pyopt= [func(i, popt[0],popt[1]) for i in Data_X]
        plt.plot(Data_X, Y_pyopt, 'r-', label= 'Scipy optimize curve-fit method')
        T_37_pyopt = np.log(0.37/popt[0])/(-1*popt[1])
        plt.axvline(x=T_37_pyopt, color='r', linestyle='--', alpha=0.3, label=r'$t_{37}$ for Scipy optimize curve-fit')
         
        # Using the programmed Levenberg-Marquardt for parameter estimation and then plotting and calculating the corresponding t_37
        # In the input of the method p=[0,0] is the default and then this part is skipped. The Levenberg-Marquardt has first to be 
        # executed to get the estimated parameters, these are then put in as p instead in order to plott and calculate the corresponding t_37
        if p[0] != 0:
          Y_lmp=[func(u,p[0],p[1]) for u in Data_X]
          plt.plot(Data_X, Y_lmp, 'm-', label= 'Programmed Levenberg-Marquardt method')
          T_37_plm = np.log(0.37/p[0])/(-1*p[1])
          plt.axvline(x=T_37_plm, color='m', linestyle='--', alpha=0.3, label=r'$t_{37}$ for programmed Levenberg-Marquardt')
          print("Hvorslevs method gives the hydraulic conductivity (K):"+str(Hvorslev(T_37_plm)/100)+" m/s with programmed LM.")
    
        plt.xlabel('Time unit (s)')
        plt.ylabel(r'$\frac{H}{H_0}$')
        plt.legend(fontsize = 'small')
        
        # Divid with 100 to get in m/s
        print("Hvorslevs method gives the hydraulic conductivity (K):"+str(Hvorslev(T_37_lr)/100)+" m/s with linear regression.")
        print("Hvorslevs method gives the hydraulic conductivity (K):"+str(Hvorslev(T_37_pyopt)/100)+" m/s with non-linear python curve fit.")
        
    def LM_Hvorslevs_model(self,Data_X,Data_Y):
        #Non-linear least square Levenberg-Marquardt for Hvorslev
        self.Data_X = Data_X
        self.Data_Y = Data_Y
        
        # Guess of simple function following the data
        def f(u,p1,p2):
                  return p1*np.exp(-1*p2*u)
        # Partial derivative for func at xi
        def Ji(u,p1,p2, eps=10**-8):     
            j1= (f(u,p1 + eps*p1,p2)- f(u,p1,p2))/ eps
            j2= (f(u,p1,p2 +eps*p2)- f(u,p1,p2))/ eps
            return np.array([[j1,j2]])

        # Initial values and guess
        beta= [1, 0.01]  # Initial guess of parameters
        k=0     # number of iterations starting at 0 
        kmax= 50   # max number of iterations
        v = 2      # constant 
        t= 10**3   # Initial value of constant relating to the damping
        
        #Starting the while loop and the Levenberg-Marquardt algorithm
        while k < kmax:

            F= np.asarray([f(i,beta[0],beta[1]) for i in Data_X])  # Vector with f1,f2....

            # Creating the Jacobian of the partial derivatives of f
            Jacobian= Ji(Data_X[0],beta[0], beta[1])
            for i in range(len(Data_X)-1):
                Jacobian = np.concatenate((Jacobian, Ji(Data_X[i+1],beta[0], beta[1])))

            #Picking the initial value for the damping parameter until the iterations reaches the else statement
            if k < 2:
                A = np.diag(np.transpose(Jacobian)@Jacobian)
                ylam= t * max(A) 

            #Setting up the Levenberg-Marquardt equality and calculating delta
            I = np.identity(2)
            LH= np.transpose(Jacobian)@Jacobian + ylam*I
            RH= np.transpose(Jacobian)@(Data_Y - F)
            delta= np.linalg.solve(LH,RH)

            #For the first iteration comparisons can not be preformed with earlier results
            if k==0:
                delold = delta
                beta= abs(beta + delta)
                print(beta)
                k = k + 1
            #For the remaining iterations
            else:
            #The value of p is calculated in order to check if the iteration is valied, if not the damping parameter is changed
                p= (sum((Data_Y - F)**2) - sum((Data_Y-np.asarray([f(i,beta[0]+delta[0],beta[1]+delta[1]) for i in Data_X]))**2)) / np.transpose(delta)@(ylam*delta + np.transpose(Jacobian)@(Data_Y - F))
            #If p is valid (positive) the previous sum of squares is calculated as well as the one for the current iteration
                if p >= 0:
                    Jacoold= Ji(Data_X[0],beta[0]-delold[0], beta[1]-delold[1])
                    for i in range(len(Data_X)-1):
                        Jacoold = np.concatenate((Jacoold, Ji(Data_X[i+1],beta[0]-delold[0], beta[1]-delold[1])))
                    S = sum((Data_Y - np.asarray([f(i,beta[0]-delold[0],beta[1]-delold[1]) for i in Data_X])  - Jacoold@delold)**2)
                    print(S - sum((Data_Y - F - Jacobian@delta)**2), S, sum((Data_Y - F - Jacobian@delta)**2))

                    # It is checked if the delta is smaller than a  certain limit, if yes the parameters are found
                    # since a small enough change in delta gives no more value change for the parameters
                    if abs(delta[0]) < 10**-15 or abs(delta[1]) < 10**-15 :
                        print(beta + delta, k)
                        break
                    #It is checked if the difference between the current and previous sum is smaller than a limit 
                    #in order to determine if the parameters giving the minimal sum of squared residuals are found.
                    if abs(S - sum((Data_Y - F - Jacobian@delta)**2)) < 10**-10:
                        print(beta + delta, k, "sum") 
                        break
                    # When the above limits are not satisfied, the damping parameter is multiplied by a walue 
                    #and the iteration continiues 
                    else:
                        ylam = ylam * max([1/3, 1 - (2* -1)**3])
                        delold= delta
                        beta = abs(beta + delta)
                        k = k + 1
                        print(beta, k)
                # The damping parameter is increased in oder to find a valid solution faster
                else:
                    v = 2*v
                    ylam = ylam * v
        #The estimated parameters are returned
        return beta
    
    def Residualcomparison_Hvorslev(self, Data_X, Data_Y, beta):
        self.Data_X = Data_X
        self.Data_Y = Data_Y
        self.beta= beta
        
        # Guess/test function for the non-linear regression
        def f(u,p1,p2):
            return p1*np.exp(-1*p2*u)
        
        # Calculating the y-values with the estimated parameters from the programmed Levenberg-Marquardt 
        Y_conlm= [f(i,beta[0],beta[1]) for i in Data_X]
        
        # Calculating the y-values with estimation by scipy
        params= [1,1]
        popt, pcov = optimize.curve_fit(f, Data_X, Data_Y, params[:], method= 'lm')
        print(popt)
        Y_pyopt= [f(i, *popt) for i in Data_X]
        
        # Calculating y-values with the linear regression
        slope, intercept, r_value, p_value, std_err = stats.linregress(Data_X, Data_Y)
        def linregg(slope, intercept, x):
            return (slope*x + intercept)
        Y_lr= [linregg(slope, intercept, i) for i in Data_X]
        
        # Plotting the different methods as well as the original data
        plt.figure()
        plt.plot(Data_X ,Data_Y, 'mo', ms= 4, alpha= 0.4, label= 'Original data')
        plt.plot(Data_X, Y_conlm, label = 'Programmed Levenberg-Marquardt method')
        plt.plot(Data_X, Y_pyopt, label= 'Scipy optimize curve-fit method')
        plt.plot(Data_X, Y_lr, label= 'Linear regression method')
        plt.xlabel('Timestep (s)')
        plt.ylabel(r'$\frac{H}{H_0}$')
        plt.legend()
        
        # Calculating the sum of the squared residulas for the three regression methods
        conlm_res= sum([(Data_Y[i]- Y_conlm[i])**2 for i in range(len(Data_X))])
        pylm_res= sum([(Data_Y[i]- Y_pyopt[i])**2 for i in range(len(Data_X))])
        linreg_res= sum([(Data_Y[i] - Y_lr[i])**2 for i in range(len(Data_X))])
        return "Sum of squared residuals for constructed method "+str(conlm_res)+', for python method '+str(pylm_res)+' and for linear regression '+str(linreg_res)
        
    def Cooper_etal(self, Data_X, Data_Y):
        self.Data_X = Data_X
        self.Data_Y = Data_Y
        
        # The Cooper-Bredehoeft-Papadopulos model with alfa and beta as input
        def F(a,b):
            Result= integrate.quad(lambda u: np.exp(-b*u**2/a)/(u*((u*special.j0(u) - 2*a*special.j1(u))**2 + (u*special.y0(u) - 2*a*special.y1(u))**2)),0, np.infty) 
            return 8*a/(np.pi**2)* Result[0]
        
        # Constructing and plotting the type curves
        a= [10**-1, 10**-2, 10**-3, 10**-4, 10**-5]
        b= np.linspace(10**-3, 100, 10000)
        plt.figure()
        Linvals= []
        for i in a:
            Y_Values= [F(i,j) for j in b]
            plt.plot(b, Y_Values, label= "alpha = "+str(i))
            plt.xscale('log')
            slope, intercept, r_value, p_value, std_err = stats.linregress(b, Y_Values)
            Linvals.append([slope, intercept])
            Y_Values= []
       
        # Preforming a linear regression on the original data
        slope, intercept, r_value, p_value, std_err = stats.linregress(Data_X, Data_Y)
        Linvals.append([slope, intercept])
        
        #Using the list Linvals to be able to numerically compare the different slope and intercept of the different curves
        print(Linvals)
        
        #Plotting the data with the type curves
        plt.plot(Data_X, Data_Y, 'bo', label= "Original Data")
        plt.xscale('log')
        plt.xlabel('log(Tt/r_c^2)')
        #plt.xlabel('log(t)')
        plt.ylabel('H/H_0')
        plt.legend()
        
    def LM_Cooper_etal(self, Data_X, Data_Y):
        # Levenberg-Marquardt method
        self.Data_X = Data_X
        self.Data_Y = Data_Y
        
        # Function for Cooper-Bredehoeft-Papadopulos model
        def f(t,S,T, r_c=2.55, r_s= 5):    
            a= abs(r_s**2*S/r_c**2)
            b= abs(T*t/r_c**2)
            I = integrate.quad(lambda u: np.exp(-b*u**2/a)/(u*((u*special.j0(u) - 2*a*special.j1(u))**2 + (u*special.y0(u) - 2*a*special.y1(u))**2)),0, np.infty) 
            return (8*a/np.pi**2)*I[0]
        
        # Partial derivative for f at xi
        def Ji(xi,T,S, eps=10**-8):     
            j1= (f(xi,S + eps*S,T)- f(xi,S,T))/ eps
            j2= (f(xi,S,T +eps*T)- f(xi,S,T))/ eps
            return np.array([[j1,j2]])

        beta= [0.01, 0.01]   # Initial guess of parameters
        k=0                  # Start of counter for while loop
        kmax= 50             # Maximun number of iterations for while loop
        v = 2                # Multiplying constant for damping parameter
        t= 10**3             # Initial constant for damping parameter
        
        while k < kmax:

            F= np.asarray([f(i,beta[0],beta[1]) for i in Data_X])  # Vector with f1,f2....fn
            
            # Creating the Jacobian of the partial derivatives of f
            Jacobian= Ji(Data_X[0],beta[0], beta[1])
            for i in range(len(Data_X)-1):    
                Jacobian = np.concatenate((Jacobian, Ji(Data_X[i+1],beta[0], beta[1])))
            
            #Picking the initial value for the damping parameter until the iterations reaches the else statement
            if k < 2:
                A = np.diag(np.transpose(Jacobian)@Jacobian)
                ylam= t * max(A) 
            
            #Setting up the Levenberg-Marquardt equality and calculating delta
            I = np.identity(2)
            LH= np.transpose(Jacobian)@Jacobian + ylam*I
            RH= np.transpose(Jacobian)@(Data_Y - F)
            delta= np.linalg.solve(LH,RH)
            
            #For the first iteration comparisons can not be preformed with earlier results
            if k==0:
                delold = delta
                beta= abs(beta + delta)
                print(beta)
                k = k + 1
            #For the remaining iterations
            else: 
                #The value of p is calculated in order to check if the iteration is valied, if not the damping parameter is changed 
                p= (sum((Data_Y - F)**2) - sum((Data_Y-np.asarray([f(i,beta[0]+delta[0],beta[1]+delta[1]) for i in Data_X]))**2)) / np.transpose(delta)@(ylam*delta + np.transpose(Jacobian)@(Data_Y - F))
                print(p)
                if p >= 0:
                #If p is valid (positive) the previous sum of squares is calculated as well as the one for the current iteration
                    Jacoold= Ji(Data_X[0],beta[0]-delold[0], beta[1]-delold[1])
                    for i in range(len(Data_X)-1):
                        Jacoold = np.concatenate((Jacoold, Ji(Data_X[i+1],beta[0]-delold[0], beta[1]-delold[1])))
                    S = sum((Data_Y - np.asarray([f(i,beta[0]-delold[0],beta[1]-delold[1]) for i in Data_X])  - Jacoold@delold)**2)
                    print(S - sum((Data_Y - F - Jacobian@delta)**2), S, sum((Data_Y - F - Jacobian@delta)**2))


                    # It is checked if the delta is smaller than a  certain limit, if yes the parameters are found
                    # since a small enough change in delta gives no more value change for the parameters
                    if abs(delta[0]) < 10**-10 or abs(delta[1]) < 10**-10 :
                        print(beta + delta, k)
                        break
                        
                    #It is checked if the difference between the current and previous sum is smaller than a limit 
                    #in order to determine if the parameters giving the minimal sum of squared residuals are found.
                    if abs(S - sum((Data_Y - F - Jacobian@delta)**2)) < 10**-5:
                        print(beta + delta, k, "sum") 
                        break
                    
                    # When the above limits are not satisfied, the damping parameter is multiplied by a walue 
                    #and the iteration continiues 
                    else:
                        ylam = ylam * max([1/3, 1 - (2*p -1)**3])
                        delold= delta
                        beta = abs(beta + delta)
                        k = k + 1
                        print(beta, k)
                        
                # The damping parameter is increased in oder to find a valid solution faster
                else:
                    v = 2*v
                    ylam = ylam * v
        # The estimated parameters are returned
        return beta
    
    def Residualcomparison_Cooper_etal(self,Data_X, Data_Y, beta):
        self.Data_X = Data_X
        self.Data_Y = Data_Y
        self.beta= beta
        # Function for Cooper-Bredehoeft-Papadopulos model
        def f(t,S,T, r_c=2.55, r_s= 5):    
            a= abs(r_s**2*S/r_c**2)
            b= abs(T*t/r_c**2)
            I = integrate.quad(lambda u: np.exp(-b*u**2/a)/(u*((u*special.j0(u) - 2*a*special.j1(u))**2 + (u*special.y0(u) - 2*a*special.y1(u))**2)),0, np.infty) 
            return (8*a/np.pi**2)*I[0]
            
        # Parameters from constructed method LM_Cooper_etal inserted in function
        Y_conlm= [f(i,beta[0],beta[1]) for i in Data_X]
            
        # Python algorithm for non-linear least squares with Levenberg-Marquardt method
        xa= np.asarray(Data_X)
        func= lambda u, *tpl: np.array([f(i,tpl[0],tpl[1]) for i in u])
        tpl= [0.01,0.01]   # Intitial guess, same as for own algorithm
        popt, pcov = optimize.curve_fit(func, xa, Data_Y, tpl[:], method= 'lm')
        print(popt) 
        #popt= [-2.92525264e-07,  4.70112672e-02]
        Y_pylm= [f(i,popt[0],popt[1]) for i in Data_X]
        
        # Linear regression method in Python for log(X) vs Y
        slope, intercept, r_value, p_value, std_err = stats.linregress(np.log(Data_X),Data_Y)
        Y_linreg= [intercept + slope*i for i in np.log(Data_X)]
            
            
        #Plotting a comparison with origianl data, constructed method and python method
        plt.figure()
        plt.plot(Data_X ,Data_Y, 'mo', ms= 4, alpha= 0.4, label= 'Original data')
        plt.plot(Data_X, Y_conlm, label = 'Programmed Levenberg-Marquardt method')
        plt.plot(Data_X, Y_pylm, label= 'Scipy optimize curve-fit method')
        plt.plot(Data_X, Y_linreg, label= 'Linear regression method')
        #plt.xscale('log')
        plt.xlabel('Timestep (s)')
        plt.ylabel(r'$\frac{H}{H_0}$')
        plt.legend()
        plt.show()
        
        #Calculating the sum of squared residuals for each regression method
        conlm_res= sum([(Data_Y[i]- Y_conlm[i])**2 for i in range(len(Data_X))])
        pylm_res= sum([(Data_Y[i]- Y_pylm[i])**2 for i in range(len(Data_X))])
        linreg_res = sum([(Data_Y[i]-Y_linreg[i])**2 for i in range(len(Data_X))])
        return "Sum of squared residuals for constructed method "+str(conlm_res)+", non-linear Python method "+str(pylm_res)+" and linear regression with python "+ str(linreg_res)
            
      
# In[123]:

# Parameters of  monitoring well:
Total_depth = 1090           # Total djup in document, Totdepth
Borehole_radius = 5         # Borrhålsradie in document, r_s
Well_casing_radius= 2.55  # Brunnsradie in document, r_c
Screen_length= 100          # Filter längd in document, Le 

Well = Slugtest_Well(Total_depth,Borehole_radius, Well_casing_radius, Screen_length)


# In[124]:

List_WelldatafilesB = ['b2_slug_190917160317_L1472.xlsx', 'b4_slug_190917160541_L4825.xlsx', 'b5_slug_190917160752_AP361.xlsx',
                      'b6_slug_190917160938_AP361.xlsx','b7_slug_190917161115_V9499.xlsx','b8_slug_190917161540_V9499.xlsx',
                      'b9_slug_190917161935_L4825.xlsx']

List_WelldatafilesMW = ['mw1_slug_190917162320_L1472.xlsx', 'mw2_slug_190917162523_L4825.xlsx', 'mw3-1_slug_190917162723_AP361.xlsx',
                       'mw3-2_slug_190917163005_L1472.xlsx','mw4_slug_190917163341_V9499.xlsx','mw5_slug_190917163650_AP361.xlsx']

Well.read_slugdata(List_WelldatafilesB[-1])



# In[83]:

# Plot Well data and figure out within which limits the slugtest is preformed.
plt.figure()
plt.plot(Well.slugtestdata['Seconds'], Well.slugtestdata['WaterLevel'], 'bo', ms=4)
plt.xlabel('Timestep (s)')
plt.ylabel('Water level (cm over pressure sensor)')

# In[125]:

# Once the limits where the slugtest is executed are found, insert below to use Datareform

initial_h = 607   # Initial water level right before slugtest is preformed
start= 10810      # Start of slugtest time (s)
stop = 11200      # Waterlevel is back to initial level time (s)

X, Y = Well.Datareform(initial_h,start, stop)

# Now the span of the slugtest is found and the data process so all the remaining methods for analysis can be used as wished

# In[126]:
